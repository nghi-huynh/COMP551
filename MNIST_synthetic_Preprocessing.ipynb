{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST synthetic Preprocessing \n",
    "### Here, we split the MNIST synthetic dataset into a training and validation set\n",
    "We will extract individuals numbers from the MNIST synthetic training set with their corresponding labels to add to the regular MNIST set that will be use later to train a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.datasets import mnist\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the MNIST synthetic dataset\n",
    "f = h5py.File('data/MNIST_synthetic.h5', 'r')\n",
    "train_dataset = f['train_dataset']\n",
    "train_labels = f['train_labels']\n",
    "test_dataset= f['test_dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful functions to identify single digits in an image of digit sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num(image, min_pixel=4):\n",
    "    \"\"\"\n",
    "    Take as input an image containing a sequence of written numbers and output each number in the original image\n",
    "    as a individual images\n",
    "    image: image containing the sequence number\n",
    "    min_pixel : number of pixel minimal for a section to be considered a number (initialize as a 4x4 box)\n",
    "    \"\"\"\n",
    "    image_copy = image.copy()\n",
    "    image_copy2 = image.copy()\n",
    "    \n",
    "    #Binary threshold on the  original image to highlight the are where there are numbers\n",
    "    ret, thresh = cv2.threshold(image.copy(), 1, 255,cv2.THRESH_BINARY_INV)\n",
    "    #Countour the numbers\n",
    "    _, contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    preprocessed_digits = [] #array to contain the individual numbers' images\n",
    "    \n",
    "    # We sort the countours by their position on the x axis to select the numbers in the images from left to right\n",
    "    contours_array = np.empty((0,4),dtype=int)\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c) #extract the coordinates of the box around the number\n",
    "        contours_array = np.concatenate((contours_array,[[x,y,w,h]]), axis=0)\n",
    "    columnIndex = 0\n",
    "    # Sort contour array by the first column (containing x-axis value)\n",
    "    sortedc = contours_array[contours_array[:,columnIndex].argsort()]\n",
    "    \n",
    "    for c in range(len(sortedc)):\n",
    "        x,y,w,h = sortedc[c]\n",
    "        \n",
    "        if (h<=min_pixel or w<=min_pixel or h>=60 or w>=60): \n",
    "            #eliminate countours that are too small (likely not a number) or too big (box around the whole image)\n",
    "            continue\n",
    "        \n",
    "        # Creating a rectangle around the digit in the original image (for displaying the digits fetched via contours)\n",
    "        cv2.rectangle(image_copy, (x,y), (x+w, y+h), color=100, thickness=1)\n",
    "    \n",
    "        # Cropping out the digit from the image corresponding to the current contours in the for loop\n",
    "        digit =image_copy2[y:y+h, x:x+w]\n",
    "    \n",
    "        # Resizing that digit to (24,24)\n",
    "        resized_digit = cv2.resize(digit, (24,24))\n",
    "    \n",
    "        # Padding the digit with 2 pixels in each side to produce the image of (28, 28)\n",
    "        padded_digit = np.pad(resized_digit, ((2,2),(2,2)), \"constant\", constant_values=0)\n",
    "        s\n",
    "        preprocessed_digits.append(padded_digit) \n",
    "    inp = np.array(preprocessed_digits)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_single_labels(labels):\n",
    "    \"\"\"\n",
    "    Remove the label '10' from the array of \n",
    "    \"\"\"\n",
    "    no_10 = np.delete(labels, np.where(labels == 10))\n",
    "   \n",
    "    return no_10\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct training set from modified MNIST set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modified_mnist=np.array(train_dataset)\n",
    "train_labels_modified_mnist = np.array(train_labels)\n",
    "n_test = len(train_modified_mnist)//5 #20% of the training set use for validate\n",
    "valid_modified_mnist, valid_labels_modified_mnist = train_modified_mnist[:n_test], train_labels_modified_mnist[:n_test]\n",
    "#np.save('valid_modified_mnist.npy',valid_modified_mnist)\n",
    "#np.save('valid_labels_modified_mnist.npy',valid_labels_modified_mnist)\n",
    "rest_train_modified_mnist, rest_train_labels_modified_mnist = train_modified_mnist[n_test:42000], train_labels_modified_mnist[n_test:42000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures processed so far:  1999\n",
      "Number of pictures processed so far:  3999\n",
      "Number of pictures processed so far:  5999\n",
      "Number of pictures processed so far:  7999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e27bfd3350d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m      \u001b[1;31m#Concatenate the single digit images and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mcombined_rest_train_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_rest_train_imgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mcombined_rest_train_labels\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_rest_train_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1999\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "combined_rest_train_imgs = np.empty((1, 28, 28))\n",
    "combined_rest_train_labels = np.empty((1),dtype=int)\n",
    "combined_rest_train_labels=np.delete(combined_rest_train_labels, 0)\n",
    "#loop over all the digit sequence images in the training set\n",
    "for i in range(len(rest_train_modified_mnist)):\n",
    "    inp = extract_num(rest_train_modified_mnist[i,:,:,:]) #extract single digit images\n",
    "    ind_labels = extract_single_labels(rest_train_labels_modified_mnist[i]) #extract digit labels\n",
    "    #if there is either no digits found or too many digits, then adjust the min_pixel size properly\n",
    "    min_pi=4\n",
    "    while(inp.shape[0] == 0):\n",
    "        inp = extract_num(rest_train_modified_mnist[i,:,:,:], min_pixel=min_pi-1)\n",
    "        \n",
    "    while(inp.shape[0] > 5):\n",
    "        inp = extract_num(rest_train_modified_mnist[i,:,:,:], min_pixel=min_pi+1)\n",
    "        \n",
    "     #Concatenate the single digit images and labels   \n",
    "    combined_rest_train_imgs = np.concatenate((combined_rest_train_imgs,inp), axis=0)\n",
    "    combined_rest_train_labels =np.concatenate((combined_rest_train_labels,ind_labels), axis=0)\n",
    "    if i % 2000 == 1999:\n",
    "        print('Number of pictures processed so far: ', i)\n",
    "#delete first element due to initialization (not an image)\n",
    "combined_rest_train_imgs=np.delete(combined_rest_train_imgs, 0)        \n",
    "\n",
    "\n",
    "#np.save('combined_rest_train_imgs.npy', combined_rest_train_imgs)\n",
    "#np.save('combined_rest_train_labels.npy', combined_rest_train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
